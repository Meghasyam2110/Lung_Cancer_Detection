{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "956c59e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Benign cases', 'Malignant cases', 'Normal cases']\n",
      "Train: 823 | Val: 176 | Test: 178\n",
      "Class counts in train: {'Benign cases': np.int64(140), 'Malignant cases': np.int64(392), 'Normal cases': np.int64(291)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# Set root path\n",
    "dataset_root = r\"C:/Users/sangi/Downloads/IQ-Processed/IQ-Processed\"\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=os.path.join(dataset_root, \"train\"), transform=train_transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(dataset_root, \"val\"), transform=val_test_transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(dataset_root, \"test\"), transform=val_test_transform)\n",
    "\n",
    "# Class balancing using WeightedRandomSampler\n",
    "targets = train_dataset.targets\n",
    "class_counts = np.bincount(targets)\n",
    "class_weights = 1. / class_counts\n",
    "sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Train:\", len(train_dataset), \"| Val:\", len(val_dataset), \"| Test:\", len(test_dataset))\n",
    "print(\"Class counts in train:\", dict(zip(train_dataset.classes, class_counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b74d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training MOBILENET ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\sangi/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100.0%\n",
      "Epoch 1/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:54<00:00,  4.41s/it, loss=0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6865 | Val Acc: 0.7898 | Val F1: 0.7778\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:41<00:00,  3.91s/it, loss=0.286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7764 | Val Acc: 0.8580 | Val F1: 0.8526\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:41<00:00,  3.90s/it, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8651 | Val Acc: 0.8580 | Val F1: 0.8587\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:38<00:00,  3.78s/it, loss=0.38] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8712 | Val Acc: 0.9432 | Val F1: 0.9436\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:40<00:00,  3.85s/it, loss=0.159] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9283 | Val Acc: 0.9091 | Val F1: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:39<00:00,  3.83s/it, loss=0.093] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9380 | Val Acc: 0.9034 | Val F1: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:38<00:00,  3.80s/it, loss=0.335] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9465 | Val Acc: 0.9261 | Val F1: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:38<00:00,  3.80s/it, loss=0.324] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9429 | Val Acc: 0.9489 | Val F1: 0.9475\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:39<00:00,  3.84s/it, loss=0.159] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9502 | Val Acc: 0.9432 | Val F1: 0.9427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:41<00:00,  3.92s/it, loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9648 | Val Acc: 0.9545 | Val F1: 0.9541\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:44<00:00,  4.02s/it, loss=0.0518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9648 | Val Acc: 0.9545 | Val F1: 0.9552\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:41<00:00,  3.89s/it, loss=0.0669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9781 | Val Acc: 0.9659 | Val F1: 0.9659\n",
      "‚úÖ Saved Best Model: mobilenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:47<00:00,  4.15s/it, loss=0.0941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9721 | Val Acc: 0.9602 | Val F1: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:42<00:00,  3.96s/it, loss=0.15]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9745 | Val Acc: 0.9545 | Val F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - mobilenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:43<00:00,  3.98s/it, loss=0.116]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9830 | Val Acc: 0.9659 | Val F1: 0.9656\n",
      "üìà Best Validation F1 for mobilenet: 0.9659\n",
      "\n",
      "==== Evaluating MOBILENET on Test Data ====\n",
      "\n",
      "=== Test Classification Report ===\n",
      "Benign: F1=0.9524, Precision=0.9091, Recall=1.0000\n",
      "Malignant: F1=0.9941, Precision=1.0000, Recall=0.9882\n",
      "Normal: F1=0.9839, Precision=1.0000, Recall=0.9683\n",
      "macro avg: F1=0.9768, Precision=0.9697, Recall=0.9855\n",
      "weighted avg: F1=0.9834, Precision=0.9847, Recall=0.9831\n",
      "\n",
      "Test Accuracy: 0.9831\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  0  0]\n",
      " [ 1 84  0]\n",
      " [ 2  0 61]]\n",
      "\n",
      "==== Training EFFICIENTNET ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\sangi/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100.0%\n",
      "Epoch 1/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:19<00:00,  5.38s/it, loss=0.532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6646 | Val Acc: 0.7159 | Val F1: 0.6742\n",
      "‚úÖ Saved Best Model: efficientnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:21<00:00,  5.43s/it, loss=0.456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7570 | Val Acc: 0.8068 | Val F1: 0.7993\n",
      "‚úÖ Saved Best Model: efficientnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:24<00:00,  5.54s/it, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8190 | Val Acc: 0.8466 | Val F1: 0.8467\n",
      "‚úÖ Saved Best Model: efficientnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:27<00:00,  5.66s/it, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8530 | Val Acc: 0.9261 | Val F1: 0.9283\n",
      "‚úÖ Saved Best Model: efficientnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:28<00:00,  5.72s/it, loss=0.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8955 | Val Acc: 0.9148 | Val F1: 0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:37<00:00,  6.07s/it, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9089 | Val Acc: 0.9148 | Val F1: 0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:23<00:00,  5.52s/it, loss=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9259 | Val Acc: 0.9375 | Val F1: 0.9393\n",
      "‚úÖ Saved Best Model: efficientnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:29<00:00,  5.76s/it, loss=0.388] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9247 | Val Acc: 0.8409 | Val F1: 0.8439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:27<00:00,  5.68s/it, loss=0.27]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9502 | Val Acc: 0.9261 | Val F1: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:58<00:00,  6.88s/it, loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9514 | Val Acc: 0.8977 | Val F1: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:13<00:00,  7.45s/it, loss=0.0913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9550 | Val Acc: 0.9318 | Val F1: 0.9338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - efficientnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:42<00:00,  6.25s/it, loss=0.148] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9575 | Val Acc: 0.9375 | Val F1: 0.9393\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "üìà Best Validation F1 for efficientnet: 0.9393\n",
      "\n",
      "==== Evaluating EFFICIENTNET on Test Data ====\n",
      "\n",
      "=== Test Classification Report ===\n",
      "Benign: F1=0.8169, Precision=0.7073, Recall=0.9667\n",
      "Malignant: F1=0.9941, Precision=1.0000, Recall=0.9882\n",
      "Normal: F1=0.8966, Precision=0.9811, Recall=0.8254\n",
      "macro avg: F1=0.9025, Precision=0.8961, Recall=0.9268\n",
      "weighted avg: F1=0.9297, Precision=0.9440, Recall=0.9270\n",
      "\n",
      "Test Accuracy: 0.9270\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29  0  1]\n",
      " [ 1 84  0]\n",
      " [11  0 52]]\n",
      "\n",
      "==== Training GOOGLENET ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\googlenet.py:341: UserWarning: auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them\n",
      "  warnings.warn(\n",
      "Epoch 1/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:39<00:00,  3.84s/it, loss=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6282 | Val Acc: 0.6420 | Val F1: 0.5410\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:43<00:00,  3.99s/it, loss=0.629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7813 | Val Acc: 0.7784 | Val F1: 0.7671\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:50<00:00,  4.26s/it, loss=0.426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8202 | Val Acc: 0.9091 | Val F1: 0.9089\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:34<00:00,  5.96s/it, loss=0.302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8542 | Val Acc: 0.8580 | Val F1: 0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:35<00:00,  5.99s/it, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8858 | Val Acc: 0.9034 | Val F1: 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:33<00:00,  5.91s/it, loss=0.351] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9405 | Val Acc: 0.9375 | Val F1: 0.9383\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:37<00:00,  6.06s/it, loss=0.217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9392 | Val Acc: 0.9034 | Val F1: 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:15<00:00,  5.21s/it, loss=0.19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9599 | Val Acc: 0.9489 | Val F1: 0.9494\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:22<00:00,  5.49s/it, loss=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9514 | Val Acc: 0.9659 | Val F1: 0.9662\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:01<00:00,  4.68s/it, loss=0.0724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9599 | Val Acc: 0.9602 | Val F1: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:46<00:00,  4.08s/it, loss=0.0521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9648 | Val Acc: 0.9659 | Val F1: 0.9664\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:43<00:00,  3.97s/it, loss=0.0567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9660 | Val Acc: 0.9773 | Val F1: 0.9776\n",
      "‚úÖ Saved Best Model: googlenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:02<00:00,  4.71s/it, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9733 | Val Acc: 0.9602 | Val F1: 0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [02:26<00:00,  5.65s/it, loss=0.0519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9648 | Val Acc: 0.9489 | Val F1: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - googlenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:55<00:00,  4.43s/it, loss=0.163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9793 | Val Acc: 0.9716 | Val F1: 0.9721\n",
      "üìà Best Validation F1 for googlenet: 0.9776\n",
      "\n",
      "==== Evaluating GOOGLENET on Test Data ====\n",
      "\n",
      "=== Test Classification Report ===\n",
      "Benign: F1=0.9355, Precision=0.9062, Recall=0.9667\n",
      "Malignant: F1=1.0000, Precision=1.0000, Recall=1.0000\n",
      "Normal: F1=0.9677, Precision=0.9836, Recall=0.9524\n",
      "macro avg: F1=0.9677, Precision=0.9633, Recall=0.9730\n",
      "weighted avg: F1=0.9777, Precision=0.9784, Recall=0.9775\n",
      "\n",
      "Test Accuracy: 0.9775\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29  0  1]\n",
      " [ 0 85  0]\n",
      " [ 3  0 60]]\n",
      "\n",
      "==== Training RESNET ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\sangi/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n",
      "Epoch 1/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:22<00:00,  3.16s/it, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7315 | Val Acc: 0.8239 | Val F1: 0.8144\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:22<00:00,  3.15s/it, loss=0.282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8044 | Val Acc: 0.8693 | Val F1: 0.8537\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:18<00:00,  3.02s/it, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8821 | Val Acc: 0.8636 | Val F1: 0.8682\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:16<00:00,  2.95s/it, loss=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8870 | Val Acc: 0.8068 | Val F1: 0.8045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:19<00:00,  3.04s/it, loss=0.126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9174 | Val Acc: 0.8466 | Val F1: 0.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:20<00:00,  3.11s/it, loss=0.315] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9465 | Val Acc: 0.9375 | Val F1: 0.9378\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:28<00:00,  3.42s/it, loss=0.0888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9575 | Val Acc: 0.8977 | Val F1: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:27<00:00,  3.37s/it, loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9745 | Val Acc: 0.9318 | Val F1: 0.9317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:40<00:00,  3.86s/it, loss=0.0307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9587 | Val Acc: 0.9659 | Val F1: 0.9664\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:34<00:00,  3.63s/it, loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9660 | Val Acc: 0.9773 | Val F1: 0.9775\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:27<00:00,  3.37s/it, loss=0.081] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9757 | Val Acc: 0.9659 | Val F1: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:27<00:00,  3.37s/it, loss=0.0481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9793 | Val Acc: 0.9545 | Val F1: 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:40<00:00,  3.85s/it, loss=0.0288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9721 | Val Acc: 0.9375 | Val F1: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:46<00:00,  4.10s/it, loss=0.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9769 | Val Acc: 0.9545 | Val F1: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - resnet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [01:58<00:00,  4.57s/it, loss=0.075] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9806 | Val Acc: 0.9773 | Val F1: 0.9776\n",
      "‚úÖ Saved Best Model: resnet_best.pth\n",
      "üìà Best Validation F1 for resnet: 0.9776\n",
      "\n",
      "==== Evaluating RESNET on Test Data ====\n",
      "\n",
      "=== Test Classification Report ===\n",
      "Benign: F1=0.9062, Precision=0.8529, Recall=0.9667\n",
      "Malignant: F1=1.0000, Precision=1.0000, Recall=1.0000\n",
      "Normal: F1=0.9508, Precision=0.9831, Recall=0.9206\n",
      "macro avg: F1=0.9524, Precision=0.9453, Recall=0.9624\n",
      "weighted avg: F1=0.9668, Precision=0.9692, Recall=0.9663\n",
      "\n",
      "Test Accuracy: 0.9663\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29  0  1]\n",
      " [ 0 85  0]\n",
      " [ 5  0 58]]\n",
      "\n",
      "==== Training DENSENET ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [05:02<00:00, 11.64s/it, loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7035 | Val Acc: 0.6591 | Val F1: 0.5997\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [04:41<00:00, 10.83s/it, loss=0.285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8202 | Val Acc: 0.8295 | Val F1: 0.8196\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [04:31<00:00, 10.45s/it, loss=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8578 | Val Acc: 0.8920 | Val F1: 0.8896\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:48<00:00,  8.78s/it, loss=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9162 | Val Acc: 0.9545 | Val F1: 0.9539\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:52<00:00,  8.95s/it, loss=0.207] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9356 | Val Acc: 0.9205 | Val F1: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:49<00:00,  8.83s/it, loss=0.0541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9514 | Val Acc: 0.9261 | Val F1: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:41<00:00,  8.51s/it, loss=0.0762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9575 | Val Acc: 0.9545 | Val F1: 0.9536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:44<00:00,  8.64s/it, loss=0.0305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9781 | Val Acc: 0.9659 | Val F1: 0.9660\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:44<00:00,  8.62s/it, loss=0.206] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9769 | Val Acc: 0.9545 | Val F1: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:44<00:00,  8.63s/it, loss=0.0165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9708 | Val Acc: 0.9602 | Val F1: 0.9597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:46<00:00,  8.71s/it, loss=0.251] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9891 | Val Acc: 0.9716 | Val F1: 0.9715\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:50<00:00,  8.86s/it, loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9854 | Val Acc: 0.9773 | Val F1: 0.9771\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [03:49<00:00,  8.83s/it, loss=0.0687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9830 | Val Acc: 0.9659 | Val F1: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [04:26<00:00, 10.25s/it, loss=0.226] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9854 | Val Acc: 0.9716 | Val F1: 0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - densenet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [04:11<00:00,  9.69s/it, loss=0.0486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9842 | Val Acc: 0.9886 | Val F1: 0.9887\n",
      "‚úÖ Saved Best Model: densenet_best.pth\n",
      "üìà Best Validation F1 for densenet: 0.9887\n",
      "\n",
      "==== Evaluating DENSENET on Test Data ====\n",
      "\n",
      "=== Test Classification Report ===\n",
      "Benign: F1=0.9231, Precision=0.8571, Recall=1.0000\n",
      "Malignant: F1=1.0000, Precision=1.0000, Recall=1.0000\n",
      "Normal: F1=0.9587, Precision=1.0000, Recall=0.9206\n",
      "macro avg: F1=0.9606, Precision=0.9524, Recall=0.9735\n",
      "weighted avg: F1=0.9724, Precision=0.9759, Recall=0.9719\n",
      "\n",
      "Test Accuracy: 0.9719\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  0  0]\n",
      " [ 0 85  0]\n",
      " [ 5  0 58]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model getter\n",
    "def get_model(name, num_classes=3):\n",
    "    if name == 'mobilenet':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'googlenet':\n",
    "        model = models.googlenet(pretrained=True, aux_logits=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name == 'resnet':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name == 'densenet':\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "    return model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    report = classification_report(all_labels, all_preds, target_names=['Benign', 'Malignant', 'Normal'], output_dict=True)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    return report, conf_matrix, acc\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, model_name, num_epochs=15, patience=5, lr=1e-4):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    best_f1 = 0\n",
    "    patience_counter = 0\n",
    "    save_path = f\"{model_name}_best.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - {model_name}\")\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_acc = correct / total\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        report, _, val_acc = evaluate(model, val_loader)\n",
    "        val_f1 = report['weighted avg']['f1-score']\n",
    "        print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"‚úÖ Saved Best Model: {save_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(f\"üìà Best Validation F1 for {model_name}: {best_f1:.4f}\")\n",
    "\n",
    "# After training: Test & Print Metrics\n",
    "def test_model(model, test_loader, model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    report, conf_matrix, test_acc = evaluate(model, test_loader)\n",
    "\n",
    "    print(\"\\n=== Test Classification Report ===\")\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"{label}: F1={metrics['f1-score']:.4f}, Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}\")\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ========= Main Script to Train All Models ==========\n",
    "\n",
    "model_names = ['mobilenet', 'efficientnet', 'googlenet', 'resnet', 'densenet']\n",
    "\n",
    "# You'll already have these from your earlier data loading code\n",
    "# train_loader, val_loader, test_loader\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"\\n==== Training {name.upper()} ====\")\n",
    "    model = get_model(name)\n",
    "    train_model(model, train_loader, val_loader, name)\n",
    "\n",
    "    print(f\"\\n==== Evaluating {name.upper()} on Test Data ====\")\n",
    "    test_model(model, test_loader, f\"{name}_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2140236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MOBILENET...\n",
      "Loading EFFICIENTNET...\n",
      "Loading GOOGLENET...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\googlenet.py:341: UserWarning: auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RESNET...\n",
      "Loading DENSENET...\n"
     ]
    }
   ],
   "source": [
    "# Load all trained CNN models\n",
    "model_names = ['mobilenet', 'efficientnet', 'googlenet', 'resnet', 'densenet']\n",
    "trained_models = {}\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"Loading {name.upper()}...\")\n",
    "    model = get_model(name)\n",
    "    model.load_state_dict(torch.load(f\"{name}_best.pth\"))\n",
    "    trained_models[name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9891687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracting features from MOBILENET ---\n",
      "--- Training and saving ML models on MOBILENET features ---\n",
      "Saved svm model for mobilenet at saved_models/mobilenet_svm_model.pkl\n",
      "svm on mobilenet: 0.9545\n",
      "Saved knn model for mobilenet at saved_models/mobilenet_knn_model.pkl\n",
      "knn on mobilenet: 0.9602\n",
      "Saved naive_bayes model for mobilenet at saved_models/mobilenet_naive_bayes_model.pkl\n",
      "naive_bayes on mobilenet: 0.9375\n",
      "Saved decision_tree model for mobilenet at saved_models/mobilenet_decision_tree_model.pkl\n",
      "decision_tree on mobilenet: 1.0000\n",
      "Saved random_forest model for mobilenet at saved_models/mobilenet_random_forest_model.pkl\n",
      "random_forest on mobilenet: 1.0000\n",
      "Saved adaboost model for mobilenet at saved_models/mobilenet_adaboost_model.pkl\n",
      "adaboost on mobilenet: 1.0000\n",
      "Saved mlp model for mobilenet at saved_models/mobilenet_mlp_model.pkl\n",
      "mlp on mobilenet: 0.9602\n",
      "\n",
      "--- Extracting features from EFFICIENTNET ---\n",
      "--- Training and saving ML models on EFFICIENTNET features ---\n",
      "Saved svm model for efficientnet at saved_models/efficientnet_svm_model.pkl\n",
      "svm on efficientnet: 0.9545\n",
      "Saved knn model for efficientnet at saved_models/efficientnet_knn_model.pkl\n",
      "knn on efficientnet: 0.9545\n",
      "Saved naive_bayes model for efficientnet at saved_models/efficientnet_naive_bayes_model.pkl\n",
      "naive_bayes on efficientnet: 0.9489\n",
      "Saved decision_tree model for efficientnet at saved_models/efficientnet_decision_tree_model.pkl\n",
      "decision_tree on efficientnet: 1.0000\n",
      "Saved random_forest model for efficientnet at saved_models/efficientnet_random_forest_model.pkl\n",
      "random_forest on efficientnet: 1.0000\n",
      "Saved adaboost model for efficientnet at saved_models/efficientnet_adaboost_model.pkl\n",
      "adaboost on efficientnet: 0.9602\n",
      "Saved mlp model for efficientnet at saved_models/efficientnet_mlp_model.pkl\n",
      "mlp on efficientnet: 0.9545\n",
      "\n",
      "--- Extracting features from GOOGLENET ---\n",
      "--- Training and saving ML models on GOOGLENET features ---\n",
      "Saved svm model for googlenet at saved_models/googlenet_svm_model.pkl\n",
      "svm on googlenet: 0.9773\n",
      "Saved knn model for googlenet at saved_models/googlenet_knn_model.pkl\n",
      "knn on googlenet: 0.9659\n",
      "Saved naive_bayes model for googlenet at saved_models/googlenet_naive_bayes_model.pkl\n",
      "naive_bayes on googlenet: 0.9716\n",
      "Saved decision_tree model for googlenet at saved_models/googlenet_decision_tree_model.pkl\n",
      "decision_tree on googlenet: 1.0000\n",
      "Saved random_forest model for googlenet at saved_models/googlenet_random_forest_model.pkl\n",
      "random_forest on googlenet: 1.0000\n",
      "Saved adaboost model for googlenet at saved_models/googlenet_adaboost_model.pkl\n",
      "adaboost on googlenet: 1.0000\n",
      "Saved mlp model for googlenet at saved_models/googlenet_mlp_model.pkl\n",
      "mlp on googlenet: 0.9773\n",
      "\n",
      "--- Extracting features from RESNET ---\n",
      "--- Training and saving ML models on RESNET features ---\n",
      "Saved svm model for resnet at saved_models/resnet_svm_model.pkl\n",
      "svm on resnet: 0.9886\n",
      "Saved knn model for resnet at saved_models/resnet_knn_model.pkl\n",
      "knn on resnet: 0.9773\n",
      "Saved naive_bayes model for resnet at saved_models/resnet_naive_bayes_model.pkl\n",
      "naive_bayes on resnet: 0.9716\n",
      "Saved decision_tree model for resnet at saved_models/resnet_decision_tree_model.pkl\n",
      "decision_tree on resnet: 1.0000\n",
      "Saved random_forest model for resnet at saved_models/resnet_random_forest_model.pkl\n",
      "random_forest on resnet: 1.0000\n",
      "Saved adaboost model for resnet at saved_models/resnet_adaboost_model.pkl\n",
      "adaboost on resnet: 0.9830\n",
      "Saved mlp model for resnet at saved_models/resnet_mlp_model.pkl\n",
      "mlp on resnet: 0.9886\n",
      "\n",
      "--- Extracting features from DENSENET ---\n",
      "--- Training and saving ML models on DENSENET features ---\n",
      "Saved svm model for densenet at saved_models/densenet_svm_model.pkl\n",
      "svm on densenet: 0.9830\n",
      "Saved knn model for densenet at saved_models/densenet_knn_model.pkl\n",
      "knn on densenet: 0.9886\n",
      "Saved naive_bayes model for densenet at saved_models/densenet_naive_bayes_model.pkl\n",
      "naive_bayes on densenet: 0.9886\n",
      "Saved decision_tree model for densenet at saved_models/densenet_decision_tree_model.pkl\n",
      "decision_tree on densenet: 1.0000\n",
      "Saved random_forest model for densenet at saved_models/densenet_random_forest_model.pkl\n",
      "random_forest on densenet: 1.0000\n",
      "Saved adaboost model for densenet at saved_models/densenet_adaboost_model.pkl\n",
      "adaboost on densenet: 1.0000\n",
      "Saved mlp model for densenet at saved_models/densenet_mlp_model.pkl\n",
      "mlp on densenet: 0.9886\n",
      "\n",
      "‚úÖ Final Weighted Ensemble Accuracy (Validation Set): 0.9943\n",
      "Saved ensemble weights configuration\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Set your device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create directory for saved models if it doesn't exist\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# ML classifiers\n",
    "ml_models = {\n",
    "    \"svm\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"adaboost\": AdaBoostClassifier(n_estimators=50),\n",
    "    \"mlp\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "}\n",
    "\n",
    "# Custom CNN weights\n",
    "cnn_weights = {\n",
    "    \"mobilenet\": 1.0,\n",
    "    \"resnet\": 0.7,\n",
    "    \"efficientnet\": 1.5,\n",
    "    \"googlenet\": 1.0,\n",
    "    \"densenet\": 0.7,\n",
    "}\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if isinstance(outputs, tuple):  # for models like GoogLeNet\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Flatten features\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    labels = np.hstack(labels)\n",
    "    return features, labels\n",
    "\n",
    "# Dictionary to store prediction probabilities\n",
    "final_probabilities = {}\n",
    "\n",
    "# Train ML models on CNN features and save them\n",
    "for cnn_name, cnn_model in trained_models.items():\n",
    "    print(f\"\\n--- Extracting features from {cnn_name.upper()} ---\")\n",
    "    cnn_model.to(device)\n",
    "    X_features, y_labels = extract_features(cnn_model, val_loader)\n",
    "\n",
    "    print(f\"--- Training and saving ML models on {cnn_name.upper()} features ---\")\n",
    "    model_probabilities = []\n",
    "\n",
    "    for ml_name, ml_model in ml_models.items():\n",
    "        # Train the model\n",
    "        ml_model.fit(X_features, y_labels)\n",
    "        \n",
    "        # Save the trained ML model\n",
    "        ml_model_path = f\"saved_models/{cnn_name}_{ml_name}_model.pkl\"\n",
    "        joblib.dump(ml_model, ml_model_path)\n",
    "        print(f\"Saved {ml_name} model for {cnn_name} at {ml_model_path}\")\n",
    "        \n",
    "        # Get predictions\n",
    "        y_prob = ml_model.predict_proba(X_features)\n",
    "        acc = accuracy_score(y_labels, np.argmax(y_prob, axis=1))\n",
    "        print(f\"{ml_name} on {cnn_name}: {acc:.4f}\")\n",
    "        model_probabilities.append(y_prob)\n",
    "\n",
    "    final_probabilities[cnn_name] = np.array(model_probabilities)\n",
    "\n",
    "    # Save the features for later use if needed\n",
    "    np.savez(f\"saved_models/{cnn_name}_features.npz\", \n",
    "             features=X_features, \n",
    "             labels=y_labels)\n",
    "\n",
    "# Save the CNN models if they're not already saved\n",
    "for cnn_name, cnn_model in trained_models.items():\n",
    "    model_path = f\"saved_models/{cnn_name}_model.pth\"\n",
    "    if not os.path.exists(model_path):\n",
    "        torch.save(cnn_model.state_dict(), model_path)\n",
    "        print(f\"Saved {cnn_name} model at {model_path}\")\n",
    "\n",
    "# Ensemble Voting\n",
    "voted_probabilities = np.zeros_like(final_probabilities[\"googlenet\"][0])\n",
    "\n",
    "for cnn_name, probs in final_probabilities.items():\n",
    "    weight = cnn_weights[cnn_name]\n",
    "    avg_prob = np.mean(probs, axis=0) * weight\n",
    "    voted_probabilities += avg_prob\n",
    "\n",
    "# Normalize and predict final class\n",
    "voted_probabilities /= sum(cnn_weights.values())\n",
    "voted_predictions = np.argmax(voted_probabilities, axis=1)\n",
    "\n",
    "# Final ensemble accuracy\n",
    "ensemble_accuracy = accuracy_score(y_labels, voted_predictions)\n",
    "print(f\"\\n‚úÖ Final Weighted Ensemble Accuracy (Validation Set): {ensemble_accuracy:.4f}\")\n",
    "\n",
    "# Save the ensemble voting weights for deployment\n",
    "ensemble_weights = {\n",
    "    'cnn_weights': cnn_weights,\n",
    "    'class_names': ['Benign cases', 'Malignant cases', 'Normal cases']\n",
    "}\n",
    "joblib.dump(ensemble_weights, 'saved_models/ensemble_weights.pkl')\n",
    "print(\"Saved ensemble weights configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "911ca28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 18:51:06.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.516 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-15 18:51:06.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Class names\n",
    "class_names = ['Benign cases', 'Malignant cases', 'Normal cases']\n",
    "\n",
    "# CNN Weights\n",
    "cnn_weights = {\n",
    "    \"mobilenet\": 1.0,\n",
    "    \"resnet\": 0.7,\n",
    "    \"efficientnet\": 1.5,\n",
    "    \"googlenet\": 1.0,\n",
    "    \"densenet\": 0.7,\n",
    "}\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load all CNN models\n",
    "def get_model(name, num_classes=3):\n",
    "    if name == 'mobilenet':\n",
    "        model = models.mobilenet_v2(pretrained=False)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(pretrained=False)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif name == 'googlenet':\n",
    "        model = models.googlenet(pretrained=False, aux_logits=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name == 'resnet':\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name == 'densenet':\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "    return model\n",
    "\n",
    "@st.cache_resource\n",
    "def load_cnn_models():\n",
    "    model_dict = {}\n",
    "    for name in cnn_weights.keys():\n",
    "        model = get_model(name)\n",
    "        model_path = f\"saved_models/{name}_model.pth\"\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        model_dict[name] = model\n",
    "    return model_dict\n",
    "\n",
    "def extract_features_single(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        if isinstance(output, tuple):  # GoogLeNet\n",
    "            output = output[0]\n",
    "        output = output.view(output.size(0), -1)\n",
    "        return output.cpu().numpy()\n",
    "\n",
    "def ensemble_predict(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    cnn_models = load_cnn_models()\n",
    "    total_prob = np.zeros((1, 3))\n",
    "\n",
    "    for cnn_name, model in cnn_models.items():\n",
    "        features = extract_features_single(model, image_tensor)\n",
    "        probs_list = []\n",
    "\n",
    "        for ml_name in ['svm', 'knn', 'naive_bayes', 'decision_tree', 'random_forest', 'adaboost', 'mlp']:\n",
    "            ml_model_path = f\"saved_models/{cnn_name}_{ml_name}_model.pkl\"\n",
    "            if os.path.exists(ml_model_path):\n",
    "                ml_model = joblib.load(ml_model_path)\n",
    "                probs = ml_model.predict_proba(features)\n",
    "                probs_list.append(probs)\n",
    "\n",
    "        if probs_list:\n",
    "            avg_prob = np.mean(probs_list, axis=0)\n",
    "            weighted_prob = avg_prob * cnn_weights[cnn_name]\n",
    "            total_prob += weighted_prob\n",
    "\n",
    "    # Normalize\n",
    "    total_prob /= sum(cnn_weights.values())\n",
    "    final_pred = np.argmax(total_prob)\n",
    "    return final_pred, total_prob[0]\n",
    "\n",
    "# ===== Streamlit UI =====\n",
    "st.set_page_config(page_title=\"Lung Cancer Detection - Ensemble App\", layout=\"centered\")\n",
    "st.title(\"ü´Å Lung Cancer Detection using Ensemble Learning\")\n",
    "st.write(\"Upload a CT scan image to detect possible lung cancer.\")\n",
    "\n",
    "uploaded_image = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_image is not None:\n",
    "    image = Image.open(uploaded_image).convert(\"RGB\")\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    if st.button(\"üîç Predict\"):\n",
    "        with st.spinner(\"Analyzing with ensemble model...\"):\n",
    "            pred_class, pred_probs = ensemble_predict(image)\n",
    "            st.success(f\"üéØ **Prediction**: {class_names[pred_class]}\")\n",
    "            st.write(\"### üß™ Prediction Probabilities:\")\n",
    "            for i, cls in enumerate(class_names):\n",
    "                st.write(f\"{cls}: {pred_probs[i]*100:.2f}%\")\n",
    "\n",
    "            # Optional: Display mock classification report structure\n",
    "            predicted_label = pred_class\n",
    "            true_label = pred_class  # Assume prediction for uploaded unknown\n",
    "            report = classification_report(\n",
    "    [true_label], [predicted_label],\n",
    "    labels=[0, 1, 2],\n",
    "    target_names=class_names,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "            st.write(\"### üìä Classification Report\")\n",
    "            for label in class_names:\n",
    "                st.write(f\"**{label}** ‚Äî Precision: {report[label]['precision']:.2f}, Recall: {report[label]['recall']:.2f}, F1: {report[label]['f1-score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea776bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d503ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run sdp_app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
